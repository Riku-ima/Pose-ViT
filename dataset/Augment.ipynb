{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "51bfb8d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%matplotlibo.inline` not found.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from vidaug import augmentors as vidaug\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import PIL.Image as im\n",
    "import json\n",
    "%matplotlibo.inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "fcfb4021",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from IPython.display import Video\n",
    "\n",
    "\n",
    "def Test_Play(path='./dataset/examples/'):\n",
    "    Path=sorted(glob.glob(os.path.join(path,'*.mp4')))\n",
    "    Video(Path[10])\n",
    "\n",
    "\n",
    "#idx返す?\n",
    "def keystoint(x):\n",
    "    return {int(k): v for k,v in x.items()}\n",
    "\n",
    "\n",
    "def get_rotate(frame,width,height,degree):\n",
    "    #Affine用の行列を指定        \n",
    "    rotation_mat=cv2.getRotationMatrix2D((width/2,height/2),degree,1)\n",
    "    #Affine変換\n",
    "    rotate_frame=cv2.warpAffine(frame,rotation_mat,(width,height))\n",
    "    return rotate_frame\n",
    "\n",
    "def get_translate(frame,width,height,translate):\n",
    "    Mat=np.float32([[1,0,translate[0]],[0,1,translate[1]]])\n",
    "    translate_frame=cv2.warpAffine(frame,Mat,(width,height))\n",
    "    return translate_frame\n",
    "\n",
    "\n",
    "\n",
    "def Augment_tools(path,out_dir,video_id,degree=None,translate=None):\n",
    "    \"\"\"\n",
    "    回転はdegree 指定\n",
    "    平行移動はtranslate 指定\n",
    "    \"\"\"\n",
    "    \n",
    "    cap=cv2.VideoCapture(path)\n",
    "    fps=int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    frames=cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    \n",
    "    frame_width,frame_height=int(cap.get(3)),int(cap.get(4))\n",
    "    fourc=cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    \n",
    "    if degree is not None:\n",
    "        save_path=out_dir+video_id+'_rotate_'+str(degree)+'.mp4'\n",
    "    elif translate is not None:\n",
    "        save_path=out_dir+video_id+'_translate_'+str(translate[0]) +\"_\" + str(translate[1]) + \".mp4\"\n",
    "    Video_writer=cv2.VideoWriter(save_path,fourc,fps,(frame_width,frame_height))\n",
    "    \n",
    "    \n",
    "    while (cap.isOpened()):\n",
    "        ret,frame=cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        if degree is not None:\n",
    "            out_frame=get_rotate(frame,frame_width,frame_height,degree)\n",
    "        elif translate is not None:\n",
    "            out_frame=get_translate(frame,frame_width,frame_height,translate)\n",
    "        Video_writer.write(out_frame)\n",
    "    cap.release()\n",
    "    Video_writer.release()\n",
    "\n",
    "    \n",
    "def AugmentVideos(annotation_dict,labels_dict,data_dir='./dataset/examples/',\n",
    "                 out_dir='./dataset/augment-examples/'):\n",
    "    \"\"\"\n",
    "    Annotation_dict  dict形式  'video_id':cls_label　のセット\n",
    "    \n",
    "    labels_dict     cls_label : action name\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    with open(annotation_dict) as f:\n",
    "        annotation_dict=json.load(f)\n",
    "        video_list=sorted(list(annotation_dict.items()))\n",
    "        \n",
    "    with open(labels_dict) as f:\n",
    "        #object hook１を使用して　keyとvalueを返す\n",
    "        labels_dict=json.load(f,object_hook=keystoint)\n",
    "    \n",
    "    #Visualize  each actions  numbers\n",
    "    count_dict=dict()\n",
    "    for key in annotation_dict:\n",
    "        if labels_dict[annotation_dict[key]] in count_dict:\n",
    "            count_dict[labels_dict[annotation_dict[key]]]+=1\n",
    "        else:\n",
    "            count_dict[labels_dict[annotation_dict[key]]]=1\n",
    "            \n",
    "\n",
    "    sorted_dict={k:v for k,v in sorted(count_dict.items(),key=lambda item:item[1])}\n",
    "    filterd_list=[k for k,v in sorted_dict.items() if v <=2000]\n",
    "     \n",
    "    print(sorted_dict)\n",
    "    \n",
    "    #Augment 実施\n",
    "    augmented_annotation=dict()\n",
    "    pbar=tqdm(video_list)\n",
    "    i=0\n",
    "    for video_id,label in pbar:\n",
    "        path=data_dir+video_id+'.mp4'        \n",
    "        \n",
    "        if labels_dict[label] in  filterd_list:\n",
    "            augmented_annotation[video_id+'_rotate_30']=label\n",
    "            Augment_tools(path,out_dir,video_id,degree=30)\n",
    "            augmented_annotation[video_id+'_rotate_330']=label\n",
    "            Augment_tools(path,out_dir,video_id,degree=330)\n",
    "\n",
    "            augmented_annotation[video_id + \"_translate_32_0\"] = label\n",
    "            Augment_tools(path, out_dir, video_id, translate=(32, 0))\n",
    "            augmented_annotation[video_id + \"_translate_-32_0\"] = label\n",
    "            Augment_tools(path, out_dir, video_id, translate=(-32, 0))\n",
    "        i+=1\n",
    "        pbar.set_description('Percentage {}'.format(i/len(video_list)))\n",
    "        \n",
    "        with open('./Test_dataset/augment_annotation_dict','w') as fp:\n",
    "            json.dump(augmented_annotation,fp)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "02efe9e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'shoot': 426, 'pick': 712, 'block': 996, 'pass': 1070, 'ball in hand': 2362, 'dribble': 3490, 'defense': 3866, 'run': 5924, 'no_action': 6490, 'walk': 11749}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Percentage 1.0: 100%|███████████████████████████████████████████████████████████████████████████████████████████████| 37085/37085 [05:01<00:00, 122.93it/s]\n"
     ]
    }
   ],
   "source": [
    "annotation_dict='./annotation_dict.json'\n",
    "labels_dict='./labels_dict2.json'\n",
    "data_dir='./examples/'\n",
    "out_dir='../Test_dataset/augment_dataset/'\n",
    "AugmentVideos(annotation_dict,labels_dict,data_dir=data_dir,out_dir=out_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13dd3af2",
   "metadata": {},
   "source": [
    "## Augment結果の確認\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106500c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_dict='./Test_dataset/augment_annotation_dict'\n",
    "labels_dict='./dataset/labels_dict2.json'\n",
    "with open(annotation_dict) as f:\n",
    "    annotation_dict=json.load(f)\n",
    "    video_list=sorted(list(annotation_dict.items()))\n",
    "with open(labels_dict) as f:\n",
    "    labels_dict=json.load(f,object_hook=keystoint)\n",
    "count_dict=dict()\n",
    "for key in annotation_dict:\n",
    "    if labels_dict[annotation_dict[key]] in count_dict:\n",
    "        count_dict[labels_dict[annotation_dict[key]]]+=1\n",
    "    else:\n",
    "        count_dict[labels_dict[annotation_dict[key]]]=1\n",
    "sorted_dict={k:v for k,v in sorted(count_dict.items(),key=lambda item:item[1])}\n",
    "print(sorted_dict)\n",
    "\n",
    "video_path=glob.glob('./Test_dataset/augment_dataset/*.mp4')\n",
    "print(len(video_path))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
