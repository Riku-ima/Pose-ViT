{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a238f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay\n",
    "import numpy as np\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa09eefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "### save_weights\n",
    "\n",
    "def save_weights(model,args,epoch,optim):\n",
    "    state={\n",
    "        'epoch':epoch,\n",
    "        'state_dict':model.state_dict(),\n",
    "        'optimizer':optim.state_dict()}\n",
    "    if not os.path.exists(args.model_path):\n",
    "        os.mkdir(args.model_path)\n",
    "    model_name='{}_{}epoch'.format(args.base_model,epoch)\n",
    "    torch.save(state,'{}/{}.pt'.format(args.model_path,model_name))\n",
    "    return model_name\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "def load_weights(model,args):\n",
    "    #epoch=args.start_epoch\n",
    "    epoch=1\n",
    "    pretrained=torch.load('{}/{}_{}.pt'.format(args.model_path,args.base_model,epoch))['state_dict']\n",
    "    \n",
    "    model_dict=model.state_dict()\n",
    "    pretrained={k: v for k,v in pretrained.items() if k in model_dict}\n",
    "    model_dict.update(pretrained)\n",
    "    model.load_state_dict(model_dict)\n",
    "    \n",
    "    return model\n",
    "\"\"\"\n",
    "def write_history(\n",
    "                    args,\n",
    "                    epoch,\n",
    "                    train_loss,train_acc,train_f1,train_precision,train_recall,train_confusion_matrix,\n",
    "                    val_loss,val_acc,val_f1,val_precision,val_recall,val_confusion_matrix,best_acc):\n",
    "    #.txt fileに出力  trainの情報+confusion_matrix ,val ....\n",
    "    \"\"\"\n",
    "    hitory_path: history path for save\n",
    "    \"\"\"\n",
    "    history_path=args.history_path+args.base_model+'.txt'\n",
    "    with open(history_path,'a') as file:\n",
    "        #ループ初回は書き込み\n",
    "        if epoch ==1:\n",
    "            file.write(\n",
    "                '=========================  {}  =========================\\n'.format(args.base_model)\n",
    "                +str(args)\n",
    "                      )\n",
    "            \n",
    "        \n",
    "        file.write('checkpoint_name:{} {}epoch lr:{}\\n'.format(args.base_model,epoch,args.lr)\n",
    "        +'train_loss: {} || train_acc: {} || train_f1: {} || train_precision: {} || train_recall: {}\\n'.format(\n",
    "        round(train_loss,5),round(train_acc,5),round(train_f1,5),round(train_precision,5),round(train_recall,5))\n",
    "        +train_confusion_matrix+'\\n'\n",
    "                   \n",
    "        + 'val_loss: {} || val_acc: {} || val_f1: {} || val_precision: {} || val_recall: {}\\n'.format(\n",
    "            round(val_loss,5),round(val_acc,5),round(val_f1,5),round(val_precision,5),round(val_recall,5))\n",
    "        +val_confusion_matrix+'\\n'  \n",
    "        +'BEST VAL Acc :   {:.4f}'.format(best_acc)\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd7152eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imanishi/3Ddensenet/models/densenet.py:114: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  m.weight=nn.init.kaiming_normal(m.weight,mode='fan_out')\n"
     ]
    }
   ],
   "source": [
    "model=densenet.generate_model(121)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d6436cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def Get_scores(pred_classes,ground_truths,score_type='macro'):\n",
    "    #get Acc , Precision , recall , F\n",
    "    \"\"\"\n",
    "    input:  \n",
    "          pred_classes\n",
    "          ground_truths\n",
    "          score_type : in [None,'macro','micro',]\n",
    "          \n",
    "    \"\"\"\n",
    "    acc=sklearn.metrics.accuracy_score(ground_truths,pred_classes)\n",
    "    precision=sklearn.metrics.precision_score(ground_truths,pred_classes,average=score_type)\n",
    "    recall=sklearn.metrics.recall_score(ground_truths,pred_classes,average=score_type)\n",
    "    f1=sklearn.metrics.f1_score(ground_truths,pred_classes,average=score_type)\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    labels=['0','1','2','3','4','5','6','6','7','8','9']\n",
    "    cm=confusion_matrix(y_test, y_pred)\n",
    "    cm=pd.DataFrame(data=cm, index=[\"setosa\", \"versicolor\", \"virginica\"], columns=[\"setosa\", \"versicolor\", \"virginica\"])\n",
    "    sns.heatmap(cm,square=True,cbar=True,annot=True,cmap='Blues')\n",
    "    plt.xlabel('True label',fontsize=13,rotation=0)\n",
    "    plt.ylabel('Predicted label',fontsize=13)\n",
    "    file='../history/'+'heatmap.png'\n",
    "    plt.savefig(file)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    return acc,precision,recall,f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a924ec6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
